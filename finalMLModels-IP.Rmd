---
title: "Final Project ML Model Creation"
author: "Jackson Gasperack"
date: "2025-11-19"
format:
  pdf:
    toc: true
---

```{r}
load(file = "EDA.RData")
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Front Matter
```{r}
#| label: frontMatter

# Add libraries
library(tidyverse)
library(ggplot2)
library(caret)
library(glmnet)
library(randomForest)
library(FNN)
library(pROC)
library(nnet)

```

Mentioned in class:

Models:
Simple/Multiple Regression, Logistic Regression, Binomial Regression, k-Nearest Neighbors (Regression/Classification), Na√Øve Bayes, SVM, Spline Regression, Neural Networks

Model Evaluations:
RMSE, k-fold Cross Validation, Confusion Matrix (Accuracy, Recall, ...), ROC Curves, AUC, R-squared, Subset Selection (Forward, Backward), Shrinkage (LASSO, Ridge), AIC, BIC, MAE, Bootstrap Validation

NOT Mentioned in class:

Models:
RandomForest, XGBoost, Poisson/Gamma Regression, t-SNE, PCA, k-Means

Model Evaluations:
Precision-Recall Curve, F1 Score, MAPE

## Question

Can we use the stats of the last 12 years to predict who will be in the final four for March Madness?

## New variable

```{r}
#| label: newVar

cbb <- cbb %>%
  mutate(
    isFinalFour = ifelse(POSTSEASON %in% c("Champions","2ND","F4"), 1, 0),
    isFinalFour = ifelse(is.na(POSTSEASON), 0, isFinalFour),
    POSTSEASON = ifelse(is.na(POSTSEASON), "No Playoffs", POSTSEASON),
    SEED = ifelse(is.na(SEED), "No Seeding", SEED)
  )
```


## Find best feature set

```{r}
#| label: featureSelection
#| results: 'hide'

# Backwards subset selection
full_model <- glm(isFinalFour ~ CONF + W + ADJOE + ADJDE + BARTHAG + EFG_O +
                   EFG_D + TOR + TORD + ORB + DRB + FTR + FTRD + `2P_O` +
                   `2P_D` + `3P_O` + `3P_D` + ADJ_T + SEED,
                 data = cbb,
                 family = binomial)

null_model <- glm(isFinalFour ~ 1, data = cbb, family = binomial)

forward_selection <- step(null_model, 
                          scope = list(lower = null_model,
                                       upper = full_model),
                          direction = "forward")

backward_selection <- step(full_model, direction = "backward")

stepwise_selection <- step(full_model, direction = "both")

print(summary(forward_selection))
print(summary(backward_selection))
print(summary(stepwise_selection))
```
Forward model is the one we'll move forward with, lowest AIC.
X = W, ADJOE, TOR, FTR, 2P_D, 2P_O, and BARTHAG but since it's not statistically significant we will try and replace it with some other variables

```{r}
#| label: modelTesting

model1 <- glm(isFinalFour ~ W + ADJOE + TOR + FTR + `2P_D` + `2P_O` + ADJDE + TORD,
              data = cbb,
              family = "binomial")

summary(model1)
```
Found model1 adds two more predictors to reduce underfitting while also decreasing AIC

## kNN

```{r}
#| label: kNearestNeighbors

features <- c("W","ADJOE","ADJDE","2P_O","2P_D","TOR","TORD","FTR")
max_k <- 30
num_folds <- 10
folds <- cut(1:nrow(cbb), breaks = num_folds, labels = FALSE)

f1_vec <- rep(NA, max_k) # w/ rare successes just accuracy is misleading

set.seed(1234) # Reproducibility
folds <- sample(folds) # k-fold CV on sample
set.seed(NULL)

# Train and test data
for(i in 1:max_k){
  fold_f1 <- rep(NA,num_folds)
  
    for(j in 1:num_folds){
    test_ind <- which(folds == j)
    train_data <- cbb[-test_ind,c(features,"isFinalFour")]
    test_data <- cbb[test_ind,c(features,"isFinalFour")]
    
    X_train <- train_data[,features]
    X_test <- test_data[,features]
    y_train <- train_data$isFinalFour
    y_test <- test_data$isFinalFour
    
    # Scale features
    X_train_scaled <- scale(X_train)
    X_test_scaled <- scale(X_test, center = attr(X_train_scaled, "scaled:center"),
                                   scale = attr(X_train_scaled, "scaled:scale"))
    
    # kNN classifier 
    pred <- knn(X_train_scaled, X_test_scaled, cl = y_train, k = i)
    cm <- table(Predicted = pred, Actual = y_test)
    
    TP <- ifelse("1" %in% rownames(cm) & "1" %in% colnames(cm), cm["1","1"], 0)
    FP <- ifelse("1" %in% rownames(cm) & "0" %in% colnames(cm), cm["1","0"], 0)
    FN <- ifelse("0" %in% rownames(cm) & "1" %in% colnames(cm), cm["0","1"], 0)
  
    precision <- ifelse((TP + FP) > 0, TP/(TP+FP), 0)
    recall <- ifelse((TP + FN) > 0, TP/(TP+FN), 0)
    fold_f1[j] <- ifelse((precision + recall) > 0, 
                       2 * precision * recall / (precision + recall),
                       0)
    }
  
  f1_vec[i] <- mean(fold_f1)
}

best_k = which.max(f1_vec)
best_k
f1_vec[best_k]

# Find accuracy of k = 3
knn_model <- knn(X_train_scaled, X_test_scaled, cl = y_train, k = 3)
acc_k3 <- mean(knn_model == y_test)
acc_k3
```

```{r}
#| label: f1VSk

f1_k_df <- data.frame(
  k=1:max_k,
  f1=f1_vec
)

ggplot(data = f1_k_df, mapping = aes(x = k, y = f1)) +
  geom_line() +
  geom_point(alpha = 0.8, color = "red") +
  labs(title = "F1 Score vs. k-Value",
       subtitle = "F1 = (2*Recall*Precision)/(Recall + Precision)",
       x = "k-Value for kNN model",
       y = "F1 Score") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 14),
        plot.subtitle = element_text(face = "italic", hjust = 0.5, size = 10),
        )
```

## Neural Networks

```{r}
# This time we won't use k-fold for our sampling

set.seed(1234)
train_inds_NN <- sample(1:nrow(cbb),.85*nrow(cbb)) # 85/15 split
set.seed(NULL)

train_NN <- cbb[train_inds_NN,c(features,"isFinalFour")]
test_NN <- cbb[-train_inds_NN,c(features,"isFinalFour")]

# split into x and y
X_train <- scale(train_NN[,features])
X_test <- scale(test_NN[,features], 
                center = attr(X_train, "scaled::center"),
                scale = attr(X_train, "scaled::scale"))

y_train <- train_NN$isFinalFour
y_test <- test_NN$isFinalFour
```

